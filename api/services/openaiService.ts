/**
 * Servicio para integraci√≥n con OpenAI API
 */
import OpenAI from 'openai';
import { TARGET_BRANDS, COMPETITOR_BRANDS, PRIORITY_SOURCES, ANALYSIS_QUESTIONS, type QuestionCategory, type SentimentType } from '../config/constants.js';
import { cacheService } from './cacheService.js';

// Nuevos tipos para an√°lisis m√°s sofisticado
export type AIModelPersona = 'chatgpt' | 'claude' | 'gemini' | 'perplexity';

export type DetailedSentiment = 'very_positive' | 'positive' | 'neutral' | 'negative' | 'very_negative';

export interface ContextualAnalysis {
  sentiment: DetailedSentiment;
  confidence: number;
  reasoning: string;
  competitivePosition: 'leader' | 'follower' | 'neutral' | 'not_mentioned';
  contextType: 'comparison' | 'standalone' | 'recommendation' | 'review' | 'news';
}

export interface MultiModelAnalysis {
  modelPersona: AIModelPersona;
  response: string;
  brandMentions: BrandMention[];
  overallSentiment: DetailedSentiment;
  contextualAnalysis: ContextualAnalysis[];
  confidenceScore: number;
}

export interface AnalysisSource {
  url: string;
  title: string;
  snippet: string;
  domain: string;
  isPriority: boolean;
  fullContent?: string; // Contenido completo extra√≠do del LLM
}

export interface BrandMention {
  brand: string;
  mentioned: boolean;
  frequency: number;
  context: SentimentType;
  evidence: string[];
  // Nuevos campos para an√°lisis m√°s sofisticado
  detailedSentiment?: DetailedSentiment;
  contextualAnalysis?: ContextualAnalysis;
  competitiveComparison?: {
    comparedWith: string[];
    position: 'better' | 'worse' | 'equal' | 'not_compared';
    reasoning: string;
  };
}

export interface QuestionAnalysis {
  questionId: string;
  question: string;
  category: string;
  summary: string;
  sources: AnalysisSource[];
  brandMentions: BrandMention[];
  sentiment: SentimentType;
  confidenceScore: number;
  // Nuevos campos para an√°lisis multi-modelo
  multiModelAnalysis?: MultiModelAnalysis[];
  detailedSentiment?: DetailedSentiment;
  contextualInsights?: string;
  competitiveAnalysis?: {
    targetBrandPosition: string;
    competitorComparisons: Array<{
      competitor: string;
      comparison: string;
      advantage: 'target' | 'competitor' | 'neutral';
    }>;
  };
}

export interface AnalysisResult {
  analysisId: string;
  timestamp: string;
  categories: QuestionCategory[];
  questions: QuestionAnalysis[];
  overallConfidence: number;
  totalSources: number;
  prioritySources: number;
  brandSummary: {
    targetBrands: BrandMention[];
    competitors: BrandMention[];
  };
  // Nuevo: Comparativas separadas por tipo de pregunta
  brandSummaryByType?: {
    all: {
      targetBrands: BrandMention[];
      competitors: BrandMention[];
    };
    generic: {
      targetBrands: BrandMention[];
      competitors: BrandMention[];
    };
    specific: {
      targetBrands: BrandMention[];
      competitors: BrandMention[];
    };
  };
}

class OpenAIService {
  private client: OpenAI;
  private userApiKeys?: {
    openai?: string;
    anthropic?: string;
    google?: string;
  };

  // Configuraci√≥n de procesamiento paralelo (OPTIMIZADO PARA VELOCIDAD)
  private readonly CONCURRENT_REQUESTS = 15; // N√∫mero de peticiones simult√°neas (aumentado de 5 a 15)
  private readonly MAX_RETRIES = 2; // Intentos m√°ximos por petici√≥n
  private readonly REQUEST_TIMEOUT = 60000; // 60 segundos
  private readonly ENABLE_CACHE = true; // Habilitar cach√©

  // Configuraci√≥n de modelos (OPTIMIZADO PARA CALIDAD Y COSTO)
  private readonly GENERATION_MODEL = "gpt-4o"; // Modelo principal para GENERAR respuestas de IA (calidad)
  private readonly ANALYSIS_MODEL = "gpt-4o-mini"; // Modelo econ√≥mico para ANALIZAR menciones (costo)
  private readonly DEFAULT_MODEL = "gpt-4o"; // Fallback por compatibilidad

  constructor(userApiKeys?: { openai?: string; anthropic?: string; google?: string }) {
    this.userApiKeys = userApiKeys;

    // Usar API key del usuario o del sistema
    const apiKey = userApiKeys?.openai || process.env.OPENAI_API_KEY;

    // Debug: Log API key status
    console.log('üîß OpenAIService constructor:')
    console.log('- Using user API key:', !!userApiKeys?.openai)
    console.log('- API key exists:', !!apiKey)
    console.log('- API key length:', apiKey?.length || 0)
    console.log('- API key starts with sk-:', apiKey?.startsWith('sk-') || false)

    if (!apiKey) {
      throw new Error('No API key available. Please provide a user API key or set OPENAI_API_KEY environment variable')
    }

    this.client = new OpenAI({
      apiKey: apiKey,
    });

    console.log('‚úÖ OpenAI client initialized successfully')
    console.log(`‚öôÔ∏è Configuraci√≥n: Concurrencia=${this.CONCURRENT_REQUESTS}, Cache=${this.ENABLE_CACHE}`)
    console.log(`ü§ñ Modelos configurados:`)
    console.log(`   - Generaci√≥n de respuestas: ${this.GENERATION_MODEL} (calidad)`)
    console.log(`   - An√°lisis de menciones: ${this.ANALYSIS_MODEL} (econ√≥mico)`)
  }

  /**
   * Procesa un array de tareas en paralelo con control de concurrencia
   */
  private async processBatch<T, R>(
    items: T[],
    processor: (item: T, index: number) => Promise<R>,
    onProgress?: (completed: number, total: number) => void
  ): Promise<R[]> {
    const results: R[] = [];
    const total = items.length;
    let completed = 0;

    console.log(`üöÄ Iniciando procesamiento paralelo: ${total} tareas, concurrencia=${this.CONCURRENT_REQUESTS}`);

    // Dividir en batches
    for (let i = 0; i < items.length; i += this.CONCURRENT_REQUESTS) {
      const batch = items.slice(i, i + this.CONCURRENT_REQUESTS);

      console.log(`üì¶ Procesando batch ${Math.floor(i / this.CONCURRENT_REQUESTS) + 1}/${Math.ceil(total / this.CONCURRENT_REQUESTS)} (${batch.length} tareas)`);

      // Procesar batch en paralelo
      const batchPromises = batch.map((item, batchIndex) =>
        processor(item, i + batchIndex)
          .then(result => {
            completed++;
            if (onProgress) {
              onProgress(completed, total);
            }
            console.log(`‚úÖ Tarea ${completed}/${total} completada (${((completed/total)*100).toFixed(1)}%)`);
            return result;
          })
          .catch(error => {
            completed++;
            console.error(`‚ùå Error en tarea ${completed}/${total}:`, error.message);
            throw error;
          })
      );

      const batchResults = await Promise.all(batchPromises);
      results.push(...batchResults);
    }

    console.log(`üéâ Procesamiento paralelo completado: ${total} tareas finalizadas`);
    return results;
  }

  /**
   * Reintenta una operaci√≥n con backoff exponencial
   */
  private async retryWithBackoff<T>(
    operation: () => Promise<T>,
    context: string,
    maxRetries: number = this.MAX_RETRIES
  ): Promise<T> {
    let lastError: Error | null = null;

    for (let attempt = 1; attempt <= maxRetries; attempt++) {
      try {
        return await operation();
      } catch (error) {
        lastError = error as Error;

        if (attempt < maxRetries) {
          const delayMs = Math.min(1000 * Math.pow(2, attempt - 1), 10000);
          console.warn(`‚ö†Ô∏è Intento ${attempt}/${maxRetries} fall√≥ para ${context}. Reintentando en ${delayMs}ms...`);
          await new Promise(resolve => setTimeout(resolve, delayMs));
        }
      }
    }

    throw lastError;
  }

  /**
   * Ejecuta an√°lisis de marca para las categor√≠as especificadas
   */
  async executeAnalysis(categories: QuestionCategory[], maxSources: number = 6): Promise<AnalysisResult> {
    const analysisId = `analysis_${Date.now()}`;
    const timestamp = new Date().toISOString();
    
    // Obtener preguntas para las categor√≠as seleccionadas
    const questionsToAnalyze = categories.flatMap(category => 
      ANALYSIS_QUESTIONS[category] || []
    );

    const questionAnalyses: QuestionAnalysis[] = [];
    
    // Procesar cada pregunta
    for (const questionData of questionsToAnalyze) {
      const analysis = await this.analyzeQuestion(questionData, maxSources);
      questionAnalyses.push(analysis);
    }

    // Calcular m√©tricas generales
    const totalSources = questionAnalyses.reduce((sum, q) => sum + q.sources.length, 0);
    const prioritySources = questionAnalyses.reduce((sum, q) => 
      sum + q.sources.filter(s => s.isPriority).length, 0
    );
    
    const overallConfidence = questionAnalyses.reduce((sum, q) => sum + q.confidenceScore, 0) / questionAnalyses.length;

    // Consolidar menciones de marca
    const brandSummary = this.consolidateBrandMentions(questionAnalyses);

    return {
      analysisId,
      timestamp,
      categories,
      questions: questionAnalyses,
      overallConfidence,
      totalSources,
      prioritySources,
      brandSummary
    };
  }

  /**
   * Ejecuta an√°lisis con configuraci√≥n completa (nueva funcionalidad)
   */
  async executeAnalysisWithConfiguration(questions: any[], configuration: any): Promise<AnalysisResult> {
    const startTime = Date.now();
    const analysisId = `analysis_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`;
    const timestamp = new Date().toISOString();
    
    console.log(`üöÄ Iniciando an√°lisis con ID: ${analysisId}`);
    console.log(`üöÄ Iniciando an√°lisis con configuraci√≥n para ${questions.length} preguntas`);
    console.log(`‚öôÔ∏è Configuraci√≥n:`, {
      model: configuration.model,
      temperature: configuration.temperature,
      maxTokens: configuration.maxTokens,
      maxSources: configuration.maxSources
    });

    const errors: string[] = [];

    let results: QuestionAnalysis[] = [];

    try {
      // Usar procesamiento paralelo optimizado con control de concurrencia
      results = await this.processBatch(
        questions,
        async (question, index) => {
          const questionStartTime = Date.now();
          console.log(`üìù [${question.id}] Iniciando an√°lisis: "${question.question.substring(0, 80)}..."`);

          try {
            // Usar retry con backoff para mayor robustez
            const result = await this.retryWithBackoff(
              () => this.analyzeQuestionWithConfiguration(question, configuration),
              `pregunta ${question.id}`,
              this.MAX_RETRIES
            );

            const questionTime = Date.now() - questionStartTime;
            console.log(`‚úÖ [${question.id}] Completado en ${questionTime}ms`);
            return result;
          } catch (error) {
            const questionTime = Date.now() - questionStartTime;
            console.error(`‚ùå [${question.id}] Error despu√©s de ${questionTime}ms:`, error);
            errors.push(`Pregunta ${question.id}: ${error}`);
            return this.createErrorAnalysis(question);
          }
        },
        (completed, total) => {
          // Callback de progreso (puede ser usado para WebSockets en el futuro)
          const percent = ((completed / total) * 100).toFixed(1);
          console.log(`üìä Progreso: ${completed}/${total} (${percent}%)`);
        }
      );

    } catch (error) {
      console.error('üî¥ Error cr√≠tico durante el procesamiento paralelo:', error);
      errors.push(`Error cr√≠tico: ${error}`);
    }

    // Consolidar menciones de marca
    console.log('üîÑ Consolidando menciones de marca...');
    const consolidatedMentions = this.consolidateBrandMentionsWithConfiguration(results, configuration);

    // Nuevo: Consolidar por tipo de pregunta
    const mentionsByType = this.consolidateBrandMentionsByQuestionType(results, configuration);

    const totalTime = Date.now() - startTime;
    const avgTimePerQuestion = results.length > 0 ? totalTime / results.length : 0;
    
    // Calcular estad√≠sticas adicionales para compatibilidad con la interfaz
    const totalSources = results.reduce((sum, result) => sum + result.sources.length, 0);
    const prioritySources = results.reduce((sum, result) => sum + result.sources.filter(s => s.isPriority).length, 0);
    const overallConfidence = results.length > 0 
      ? results.reduce((sum, result) => sum + result.confidenceScore, 0) / results.length 
      : 0;
    
    console.log(`üéØ An√°lisis completado:`);
    console.log(`   üÜî ID de an√°lisis: ${analysisId}`);
    console.log(`   ‚è±Ô∏è Tiempo total: ${totalTime}ms (${(totalTime / 1000).toFixed(2)}s)`);
    console.log(`   üìä Preguntas procesadas: ${results.length}/${questions.length}`);
    console.log(`   ‚ö° Tiempo promedio por pregunta: ${avgTimePerQuestion.toFixed(0)}ms`);
    console.log(`   ‚ùå Errores: ${errors.length}`);
    console.log(`   üè∑Ô∏è Menciones de marca consolidadas: ${consolidatedMentions.targetBrands.length + consolidatedMentions.competitors.length}`);
    console.log(`   üìà Confianza general: ${(overallConfidence * 100).toFixed(1)}%`);
    console.log(`   üìö Total de fuentes: ${totalSources} (${prioritySources} prioritarias)`);
    
    if (errors.length > 0) {
      console.warn('‚ö†Ô∏è Errores durante el an√°lisis:', errors);
    }

    return {
      analysisId,
      timestamp,
      categories: [], // Se puede agregar l√≥gica para categor√≠as si es necesario
      questions: results,
      overallConfidence,
      totalSources,
      prioritySources,
      brandSummary: consolidatedMentions,
      brandSummaryByType: mentionsByType
    };
  }

  /**
   * Analiza una pregunta espec√≠fica usando OpenAI
   */
  private async analyzeQuestion(questionData: any, maxSources: number): Promise<QuestionAnalysis> {
    const prompt = this.buildAnalysisPrompt(questionData.question, maxSources);
    
    try {
      const completion = await this.client.chat.completions.create({
        model: this.DEFAULT_MODEL,
        messages: [
          {
            role: "system",
            content: "Experto analista de mercado. Analiza informaci√≥n y detecta menciones de marcas."
          },
          {
            role: "user",
            content: prompt
          }
        ],
        temperature: 0.3,
        max_tokens: 2000
      });

      const response = completion.choices[0]?.message?.content || '';
      return this.parseAnalysisResponse(questionData, response, maxSources);
      
    } catch (error) {
      console.error('Error en an√°lisis OpenAI:', error);
      return this.createErrorAnalysis(questionData);
    }
  }

  /**
   * Obtiene el modelo de generaci√≥n a usar basado en la configuraci√≥n
   */
  private getGenerationModel(configuration: any): string {
    // Si hay un modelo seleccionado en la configuraci√≥n, usarlo
    if (configuration.selectedModel) {
      // Solo usar modelos de OpenAI para generaci√≥n (por ahora)
      const openaiModels = ['gpt-4o', 'gpt-4o-mini', 'gpt-4-turbo'];
      if (openaiModels.includes(configuration.selectedModel)) {
        return configuration.selectedModel;
      }
      // Si es un modelo de otro proveedor, usar el modelo por defecto de OpenAI
      console.log(`‚ö†Ô∏è Modelo ${configuration.selectedModel} no es de OpenAI, usando ${this.GENERATION_MODEL}`);
    }
    return this.GENERATION_MODEL;
  }

  /**
   * Construye el mensaje del sistema con contexto de pa√≠s
   */
  private buildSystemMessage(configuration: any): string {
    const industry = configuration.industry || 'sector correspondiente';
    const countryContext = configuration.countryContext || 'en Espa√±a, considerando el mercado espa√±ol';
    const countryLanguage = configuration.countryLanguage || 'Espa√±ol';

    return `Eres un experto en ${industry} ${countryContext}.
Responde siempre en ${countryLanguage}.
Proporciona informaci√≥n relevante y actualizada para ese mercado espec√≠fico.
Menciona empresas, marcas y servicios que operen en ese territorio.`;
  }

  /**
   * Analiza una pregunta espec√≠fica con configuraci√≥n personalizada y mecanismos de recuperaci√≥n
   * NUEVO ENFOQUE: Analiza respuestas generativas de ChatGPT para medir menciones de marca
   */
  private async analyzeQuestionWithConfiguration(questionData: any, configuration: any): Promise<QuestionAnalysis> {
    const questionId = questionData.id;

    // Obtener modelo din√°micamente
    const generationModel = this.getGenerationModel(configuration);

    return await this.executeWithRetry(async () => {
      console.log(`\n${'='.repeat(60)}`);
      console.log(`üîç [${questionId}] INICIANDO AN√ÅLISIS DE RESPUESTA GENERATIVA`);
      console.log(`${'='.repeat(60)}`);
      console.log(`üìù Pregunta: "${questionData.question.substring(0, 80)}..."`);
      console.log(`ü§ñ MODELO GENERACI√ìN (usuario eligi√≥): ${generationModel}`);
      console.log(`üí∞ MODELO AN√ÅLISIS (econ√≥mico fijo): ${this.ANALYSIS_MODEL}`);
      console.log(`üåç Pa√≠s: ${configuration.countryCode || 'ES'}`);
      console.log(`${'='.repeat(60)}\n`);

      try {
        console.log(`üöÄ [${questionId}] Paso 1: Generando respuesta con ${generationModel}...`);
        const startTime = Date.now();

        let generatedContent = '';

        // Generar clave de cach√© incluyendo pa√≠s y modelo
        const cacheKey = `${questionData.question}_${configuration.countryCode || 'ES'}_${generationModel}`;

        // Intentar obtener del cach√© primero
        if (this.ENABLE_CACHE) {
          try {
            const cachedResponse = await cacheService.get(
              cacheKey,
              configuration,
              generationModel
            );

            if (cachedResponse) {
              generatedContent = cachedResponse;
              const responseTime = Date.now() - startTime;
              console.log(`üíæ‚ú® [${questionId}] Respuesta obtenida del cach√© en ${responseTime}ms`);
            }
          } catch (cacheError) {
            console.warn(`‚ö†Ô∏è [${questionId}] Error al consultar cach√©:`, cacheError);
            // Continuar sin cach√©
          }
        }

        // Si no est√° en cach√©, llamar a OpenAI
        if (!generatedContent) {
          // Construir mensaje del sistema con contexto de pa√≠s
          const systemMessage = this.buildSystemMessage(configuration);

          const generativeResponse = await Promise.race([
            this.client.chat.completions.create({
              model: generationModel, // Usar modelo SELECCIONADO por el usuario
              messages: [
                {
                  role: 'system',
                  content: systemMessage
                },
                {
                  role: 'user',
                  content: questionData.question
                }
              ],
              temperature: 0.7,
              max_tokens: 2000,
            }),
            new Promise((_, reject) =>
              setTimeout(() => reject(new Error('Timeout: OpenAI request took longer than 60 seconds')), 60000)
            )
          ]) as any;

          const responseTime = Date.now() - startTime;
          generatedContent = generativeResponse.choices[0]?.message?.content || '';

          console.log(`üì® [${questionId}] Respuesta generativa recibida en ${responseTime}ms (${generatedContent.length} caracteres)`);

          // Guardar en cach√© con clave que incluye pa√≠s y modelo
          if (this.ENABLE_CACHE && generatedContent) {
            try {
              await cacheService.set(
                cacheKey,
                generatedContent,
                configuration,
                generationModel,
                7 // TTL de 7 d√≠as
              );
            } catch (cacheError) {
              console.warn(`‚ö†Ô∏è [${questionId}] Error al guardar en cach√©:`, cacheError);
              // Continuar sin guardar en cach√©
            }
          }
        }

        console.log(`üîç [${questionId}] Contenido generado: "${generatedContent.substring(0, 200)}..."`);

        if (!generatedContent || generatedContent.length < 50) {
          throw new Error('Respuesta generativa muy corta o vac√≠a');
        }

        // PASO 2: Analizar la respuesta generativa para buscar menciones de marca
        console.log(`üîç [${questionId}] Paso 2: Analizando menciones con ${this.ANALYSIS_MODEL}...`);

        const analysisPrompt = this.buildGenerativeAnalysisPrompt(questionData.question, generatedContent, configuration);

        const analysisResponse = await Promise.race([
          this.client.chat.completions.create({
            model: this.ANALYSIS_MODEL, // Usar modelo ECON√ìMICO para analizar menciones (ahorro de costos)
            messages: [{ role: 'user', content: analysisPrompt }],
            temperature: 0.1, // Baja temperatura para an√°lisis m√°s preciso
            max_tokens: 2500,
          }),
          new Promise((_, reject) =>
            setTimeout(() => reject(new Error('Timeout: Analysis request took longer than 60 seconds')), 60000)
          )
        ]) as any;

        const analysisResult = analysisResponse.choices[0]?.message?.content || '';
        console.log(`üìä [${questionId}] An√°lisis de menciones completado (${analysisResult.length} caracteres)`);

        // Validar la respuesta del an√°lisis
        if (!this.validateOpenAIResponse(analysisResult, questionId)) {
          throw new Error('Respuesta de an√°lisis no v√°lida o vac√≠a');
        }

        const analysis = this.parseGenerativeAnalysisResponse(questionData, generatedContent, analysisResult, configuration);
        console.log(`‚úÖ [${questionId}] An√°lisis de respuesta generativa completado exitosamente`);
        
        return analysis;
        
      } catch (error: any) {
        console.error(`üî¥ [${questionId}] Error en an√°lisis de respuesta generativa:`, error);
        
        // Clasificar el tipo de error para mejor manejo
        if (error.message?.includes('rate_limit')) {
          console.error(`‚è±Ô∏è [${questionId}] Rate limit alcanzado, reintentando...`);
          throw new Error(`Rate limit: ${error.message}`);
        } else if (error.message?.includes('timeout') || error.message?.includes('Timeout')) {
          console.error(`‚è∞ [${questionId}] Timeout en request, reintentando...`);
          throw new Error(`Timeout: ${error.message}`);
        } else if (error.message?.includes('insufficient_quota')) {
          console.error(`üí≥ [${questionId}] Cuota insuficiente en OpenAI`);
          throw new Error(`Quota exceeded: ${error.message}`);
        } else {
          console.error(`‚ùå [${questionId}] Error desconocido:`, error);
          throw error;
        }
      }
    }, 3, 2000, `Pregunta ${questionId}`);
  }

  /**
   * Construye el prompt optimizado para el an√°lisis con configuraci√≥n personalizada
   */
  private buildAnalysisPromptWithConfiguration(question: string, maxSources: number, configuration: any): string {
    const targetBrandsStr = configuration.targetBrands || (configuration.targetBrand ? [configuration.targetBrand] : TARGET_BRANDS);
    const competitorBrandsStr = configuration.competitorBrands || COMPETITOR_BRANDS;
    const prioritySourcesStr = configuration.prioritySources || PRIORITY_SOURCES;
    const industry = configuration.industry || 'sector correspondiente';

    // Prompt optimizado y m√°s conciso para reducir tokens
    return `Analiza esta pregunta del ${industry}:

PREGUNTA: "${question}"

MARCAS: Objetivo: ${targetBrandsStr.join(', ')} | Competidores: ${competitorBrandsStr.slice(0, 5).join(', ')}

INSTRUCCIONES:
1. An√°lisis profesional basado en conocimiento del mercado espa√±ol
2. M√°ximo ${maxSources} fuentes reales del sector
3. Identifica menciones de marcas objetivo y competidores
4. Eval√∫a sentimiento hacia cada marca

FORMATO JSON (responde SOLO con JSON v√°lido):
{
  "summary": "An√°lisis ejecutivo detallado (80-150 palabras)",
  "sources": [
    {
      "url": "URL real del sector",
      "title": "T√≠tulo espec√≠fico",
      "snippet": "Extracto relevante (50-100 palabras)",
      "domain": "dominio.com",
      "isPriority": ${prioritySourcesStr.includes('domain') ? 'true' : 'false'}
    }
  ],
  "brandMentions": [
    {
      "brand": "Nombre marca",
      "mentioned": true/false,
      "frequency": n√∫mero,
      "context": "positive/negative/neutral",
      "evidence": ["cita espec√≠fica"]
    }
  ],
  "sentiment": "positive/negative/neutral",
  "confidenceScore": 0.75-0.95
}`;
  }

  /**
   * Construye el prompt para analizar respuestas generativas en busca de menciones de marca
   */
  private buildGenerativeAnalysisPrompt(originalQuestion: string, generatedContent: string, configuration: any): string {
    const targetBrandsStr = configuration.targetBrands || (configuration.targetBrand ? [configuration.targetBrand] : TARGET_BRANDS);
    const competitorBrandsStr = configuration.competitorBrands || COMPETITOR_BRANDS;
    const countryContext = configuration.countryContext || 'en Espa√±a';
    const countryLanguage = configuration.countryLanguage || 'Espa√±ol';

    return `Analiza el siguiente contenido generado por IA para identificar menciones de marcas ${countryContext}.

PREGUNTA ORIGINAL: "${originalQuestion}"

CONTEXTO GEOGR√ÅFICO: ${countryContext}
IDIOMA: ${countryLanguage}

CONTENIDO GENERADO POR IA A ANALIZAR:
"${generatedContent}"

MARCAS A BUSCAR:
- Marcas Objetivo: ${targetBrandsStr.join(', ')}
- Competidores: ${competitorBrandsStr.slice(0, 10).join(', ')}

INSTRUCCIONES:
1. Analiza √öNICAMENTE el contenido generado por IA arriba
2. Identifica si alguna de las marcas objetivo o competidores es mencionada
3. Eval√∫a el contexto y sentimiento de cada menci√≥n
4. Determina la frecuencia y relevancia de cada menci√≥n
5. Proporciona evidencia textual espec√≠fica de las menciones
6. Ten en cuenta el contexto geogr√°fico (${countryContext}) al evaluar la relevancia

FORMATO JSON (responde SOLO con JSON v√°lido, en ${countryLanguage}):
{
  "summary": "Resumen del an√°lisis de menciones en la respuesta generativa (50-100 palabras)",
  "generatedContent": "${generatedContent.substring(0, 2000)}...",
  "brandMentions": [
    {
      "brand": "Nombre de la marca",
      "mentioned": true/false,
      "frequency": n√∫mero_de_menciones,
      "context": "positive/negative/neutral",
      "evidence": ["cita textual exacta 1", "cita textual exacta 2"],
      "relevance": "high/medium/low"
    }
  ],
  "sentiment": "positive/negative/neutral",
  "confidenceScore": 0.0-1.0,
  "analysisType": "generative_response",
  "marketContext": "${countryContext}"
}`;
  }

  /**
   * Parsea la respuesta del an√°lisis de contenido generativo
   */
  private parseGenerativeAnalysisResponse(questionData: any, generatedContent: string, analysisResponse: string, configuration: any): QuestionAnalysis {
    const questionId = questionData.id;
    
    console.log(`üîç [${questionId}] Parseando respuesta de an√°lisis generativo...`);
    console.log(`üìÑ [${questionId}] Respuesta a parsear (${analysisResponse.length} chars):`, analysisResponse.substring(0, 300));

    try {
      // Extraer JSON de la respuesta
      const jsonMatch = analysisResponse.match(/\{[\s\S]*\}/);
      if (!jsonMatch) {
        console.error(`‚ùå [${questionId}] No se encontr√≥ JSON v√°lido en la respuesta`);
        throw new Error('No se encontr√≥ JSON v√°lido en la respuesta de an√°lisis');
      }

      let jsonStr = jsonMatch[0];
      
      // Limpiar el JSON
      jsonStr = jsonStr
        .replace(/```json\s*/g, '')
        .replace(/```\s*/g, '')
        .replace(/,(\s*[}\]])/g, '$1')
        .trim();

      console.log(`üßπ [${questionId}] JSON limpiado:`, jsonStr.substring(0, 200));

      const parsedData = JSON.parse(jsonStr);
      console.log(`‚úÖ [${questionId}] JSON parseado exitosamente`);

      // Crear fuente sint√©tica que representa el contenido generativo analizado
      const syntheticSource: AnalysisSource = {
        url: 'generative-ai-response',
        title: `Respuesta Generativa: ${questionData.question.substring(0, 60)}...`,
        snippet: generatedContent.substring(0, 2000) + '...',
        domain: 'ChatGPT/OpenAI',
        isPriority: true, // Las respuestas generativas son siempre prioritarias para este an√°lisis
        fullContent: generatedContent // Guardar el contenido completo del LLM
      };

      // Procesar menciones de marca
      const brandMentions: BrandMention[] = (parsedData.brandMentions || []).map((mention: any) => ({
        brand: mention.brand || 'Desconocida',
        mentioned: mention.mentioned || false,
        frequency: mention.frequency || 0,
        context: mention.context || 'neutral',
        evidence: Array.isArray(mention.evidence) ? mention.evidence : []
      }));

      const result: QuestionAnalysis = {
        questionId: questionId,
        question: questionData.question,
        category: questionData.category || 'An√°lisis Generativo',
        summary: parsedData.summary || 'An√°lisis de respuesta generativa completado',
        sources: [syntheticSource], // Una sola "fuente" que representa el contenido generativo
        brandMentions: brandMentions,
        sentiment: parsedData.sentiment || 'neutral',
        confidenceScore: parsedData.confidenceScore || 0.5
      };

      console.log(`‚úÖ [${questionId}] An√°lisis generativo parseado: ${brandMentions.length} menciones de marca encontradas`);
      return result;

    } catch (error) {
      console.error(`‚ùå [${questionId}] Error parseando an√°lisis generativo:`, error);
      console.error(`üìÑ [${questionId}] Respuesta problem√°tica:`, analysisResponse);
      
      return this.createErrorAnalysis(questionData);
    }
  }

  /**
   * Construye el prompt de an√°lisis
   */
  private buildAnalysisPrompt(question: string, maxSources: number): string {
    const targetBrandsStr = TARGET_BRANDS.join(', ');
    const competitorBrandsStr = COMPETITOR_BRANDS.join(', ');
    const prioritySourcesStr = PRIORITY_SOURCES.join(', ');

    return `
Eres un experto analista del sector correspondiente espa√±ol. Analiza la siguiente pregunta y proporciona un an√°lisis estructurado basado en tu conocimiento del mercado espa√±ol.

PREGUNTA: "${question}"

INSTRUCCIONES:
1. Proporciona un an√°lisis detallado y profesional sobre esta pregunta
2. Identifica y analiza menciones de estas MARCAS OBJETIVO: ${targetBrandsStr}
3. Identifica y analiza menciones de estos COMPETIDORES: ${competitorBrandsStr}
4. Incluye informaci√≥n relevante de fuentes confiables como: ${prioritySourcesStr}
5. Proporciona m√°ximo ${maxSources} fuentes relevantes y reales del sector
6. Analiza el sentimiento (positivo/negativo/neutral) hacia cada marca mencionada
7. Basa tu an√°lisis en conocimiento real del mercado espa√±ol

IMPORTANTE:
- NO digas que no puedes buscar informaci√≥n en tiempo real
- Proporciona un an√°lisis profesional basado en tu conocimiento del sector
- Incluye fuentes reales y relevantes del mercado espa√±ol
- Genera contenido √∫til y espec√≠fico para la pregunta planteada

FORMATO DE RESPUESTA (JSON):
{
  "summary": "Resumen ejecutivo detallado del an√°lisis en espa√±ol, m√≠nimo 100 palabras",
  "sources": [
    {
      "url": "URL real de fuente relevante del sector",
      "title": "T√≠tulo espec√≠fico del art√≠culo/p√°gina",
      "snippet": "Extracto relevante y espec√≠fico",
      "domain": "dominio.com",
      "isPriority": true/false
    }
  ],
  "brandMentions": [
    {
      "brand": "Nombre exacto de la marca",
      "mentioned": true/false,
      "frequency": n√∫mero_de_menciones,
      "context": "positive/negative/neutral",
      "evidence": ["cita textual espec√≠fica 1", "cita textual espec√≠fica 2"]
    }
  ],
  "sentiment": "positive/negative/neutral",
  "confidenceScore": 0.7-0.95
}

Responde √öNICAMENTE con el JSON v√°lido, sin texto adicional.
    `;
  }

  /**
   * Parsea la respuesta de OpenAI con configuraci√≥n personalizada
   */
  private parseAnalysisResponseWithConfiguration(questionData: any, response: string, maxSources: number, configuration: any): QuestionAnalysis {
    try {
      console.log(`üîç [${questionData.id}] Iniciando parseo de respuesta OpenAI (${response.length} caracteres)`);
      
      // Limpiar la respuesta para extraer solo el JSON
      let cleanedResponse = response.trim();
      
      // Buscar el JSON entre ```json y ``` si existe
      const jsonCodeBlockMatch = cleanedResponse.match(/```json\s*([\s\S]*?)\s*```/);
      if (jsonCodeBlockMatch) {
        cleanedResponse = jsonCodeBlockMatch[1].trim();
        console.log(`üì¶ [${questionData.id}] JSON extra√≠do de bloque de c√≥digo`);
      }
      
      // Buscar el JSON principal
      const jsonMatch = cleanedResponse.match(/\{[\s\S]*\}/);
      if (!jsonMatch) {
        console.error(`‚ùå [${questionData.id}] No se encontr√≥ JSON v√°lido en la respuesta`);
        console.error(`üìÑ Respuesta completa:`, response);
        throw new Error('No se encontr√≥ JSON v√°lido en la respuesta');
      }

      let jsonString = jsonMatch[0];
      
      // Limpiar caracteres problem√°ticos comunes
      jsonString = jsonString
        .replace(/[\u0000-\u001F\u007F-\u009F]/g, '') // Remover caracteres de control
        .replace(/,\s*}/g, '}') // Remover comas antes de }
        .replace(/,\s*]/g, ']') // Remover comas antes de ]
        .replace(/\n/g, ' ') // Reemplazar saltos de l√≠nea con espacios
        .replace(/\r/g, '') // Remover retornos de carro
        .replace(/\t/g, ' ') // Reemplazar tabs con espacios
        .replace(/\s+/g, ' ') // Normalizar espacios m√∫ltiples
        .trim();

      console.log(`üßπ [${questionData.id}] JSON limpiado (${jsonString.length} caracteres)`);
      console.log(`üìù [${questionData.id}] Primeros 300 caracteres del JSON:`, jsonString.substring(0, 300) + '...');

      let parsed;
      try {
        parsed = JSON.parse(jsonString);
        console.log(`‚úÖ [${questionData.id}] JSON parseado exitosamente`);
      } catch (parseError) {
        console.error(`‚ùå [${questionData.id}] Error parseando JSON:`, parseError);
        console.error(`üìÑ JSON problem√°tico:`, jsonString);
        throw new Error(`Error parseando JSON: ${parseError}`);
      }
      
      // Validar estructura m√≠nima requerida
      if (!parsed.summary) {
        console.warn(`‚ö†Ô∏è [${questionData.id}] Respuesta sin summary, usando valor por defecto`);
      }
      
      const sources = (parsed.sources || []).slice(0, maxSources);
      console.log(`üìä [${questionData.id}] Procesando ${sources.length} fuentes`);

      const result = {
        questionId: questionData.id,
        question: questionData.question,
        category: questionData.category,
        summary: parsed.summary || 'An√°lisis completado sin resumen espec√≠fico',
        sources: sources.map((source: any, index: number) => {
          const processedSource = {
            url: source.url || '',
            title: source.title || `Fuente ${index + 1}`,
            snippet: source.snippet || '',
            domain: source.domain || '',
            isPriority: this.isPrioritySource(source.domain || source.url || ''),
            fullContent: source.fullContent || response || '' // Guardar contenido completo
          };
          console.log(`üîó [${questionData.id}] Fuente ${index + 1}: ${processedSource.domain} (${processedSource.isPriority ? 'prioritaria' : 'normal'})`);
          return processedSource;
        }),
        brandMentions: parsed.brandMentions || [],
        sentiment: parsed.sentiment || 'neutral',
        confidenceScore: Math.min(Math.max(parsed.confidenceScore || 0.75, 0.7), 0.95) // Mejorar confianza m√≠nima
      };
      
      console.log(`üéØ [${questionData.id}] An√°lisis parseado exitosamente - Confianza: ${(result.confidenceScore * 100).toFixed(1)}%, Fuentes: ${result.sources.length}, Marcas: ${result.brandMentions.length}`);
      
      return result;
    } catch (error) {
      console.error(`üî¥ [${questionData.id}] Error cr√≠tico parseando respuesta OpenAI:`, error);
      console.error(`üìÑ [${questionData.id}] Respuesta raw completa:`, response);
      console.error(`üìù [${questionData.id}] Pregunta que caus√≥ el error:`, questionData.question);
      console.error(`üîß [${questionData.id}] Configuraci√≥n:`, configuration);
      
      return this.createErrorAnalysis(questionData);
    }
  }

  /**
   * Parsea la respuesta de OpenAI
   */
  private parseAnalysisResponse(questionData: any, response: string, maxSources: number): QuestionAnalysis {
    try {
      console.log('Respuesta OpenAI raw:', response);
      
      // Limpiar la respuesta para extraer solo el JSON
      let cleanedResponse = response.trim();
      
      // Buscar el JSON entre ```json y ``` si existe
      const jsonCodeBlockMatch = cleanedResponse.match(/```json\s*([\s\S]*?)\s*```/);
      if (jsonCodeBlockMatch) {
        cleanedResponse = jsonCodeBlockMatch[1].trim();
      }
      
      // Buscar el JSON principal
      const jsonMatch = cleanedResponse.match(/\{[\s\S]*\}/);
      if (!jsonMatch) {
        console.error('No se encontr√≥ JSON v√°lido en la respuesta:', response);
        throw new Error('No se encontr√≥ JSON v√°lido en la respuesta');
      }

      let jsonString = jsonMatch[0];
      
      // Limpiar caracteres problem√°ticos comunes
      jsonString = jsonString
        .replace(/[\u0000-\u001F\u007F-\u009F]/g, '') // Remover caracteres de control
        .replace(/,\s*}/g, '}') // Remover comas antes de }
        .replace(/,\s*]/g, ']') // Remover comas antes de ]
        .replace(/\n/g, ' ') // Reemplazar saltos de l√≠nea con espacios
        .replace(/\r/g, '') // Remover retornos de carro
        .replace(/\t/g, ' ') // Reemplazar tabs con espacios
        .replace(/\s+/g, ' ') // Normalizar espacios m√∫ltiples
        .trim();

      console.log('JSON limpiado:', jsonString);

      const parsed = JSON.parse(jsonString);
      
      return {
        questionId: questionData.id,
        question: questionData.question,
        category: questionData.category,
        summary: parsed.summary || 'An√°lisis no disponible',
        sources: (parsed.sources || []).slice(0, maxSources).map((source: any) => ({
          url: source.url || '',
          title: source.title || '',
          snippet: source.snippet || '',
          domain: source.domain || '',
          isPriority: this.isPrioritySource(source.domain || source.url || ''),
          fullContent: source.fullContent || response || '' // Guardar contenido completo
        })),
        brandMentions: parsed.brandMentions || [],
        sentiment: parsed.sentiment || 'neutral',
        confidenceScore: Math.min(Math.max(parsed.confidenceScore || 0.75, 0.7), 0.95) // Mejorar confianza m√≠nima
      };
    } catch (error) {
      console.error(`üî¥ Error parseando respuesta OpenAI para pregunta ${questionData.id}:`, error);
      console.error(`üìÑ Respuesta raw:`, response);
      return this.createErrorAnalysis(questionData);
    }
  }

  /**
   * Verifica si una fuente es prioritaria con configuraci√≥n personalizada
   */
  private isPrioritySourceWithConfiguration(urlOrDomain: string, configuration: any): boolean {
    const domain = urlOrDomain.toLowerCase();
    const prioritySources = configuration.prioritySources || PRIORITY_SOURCES;
    return prioritySources.some((source: string) => 
      domain.includes(source.toLowerCase())
    );
  }

  /**
   * Verifica si una fuente es prioritaria
   */
  private isPrioritySource(urlOrDomain: string): boolean {
    const domain = urlOrDomain.toLowerCase();
    return PRIORITY_SOURCES.some(source => 
      domain.includes(source.toLowerCase())
    );
  }

  /**
   * Crea an√°lisis de error cuando falla el procesamiento
   */
  private createErrorAnalysis(questionData: any): QuestionAnalysis {
    console.log(`üîß [${questionData.id}] Creando an√°lisis de error para pregunta: "${questionData.question}"`);
    
    return {
      questionId: questionData.id,
      question: questionData.question,
      category: questionData.category,
      summary: 'Error al procesar el an√°lisis. El sistema no pudo generar una respuesta v√°lida para esta pregunta. Por favor, int√©ntalo de nuevo m√°s tarde o contacta con soporte t√©cnico.',
      sources: [],
      brandMentions: [],
      sentiment: 'neutral' as SentimentType,
      confidenceScore: 0.0
    };
  }

  /**
   * Implementa mecanismo de recuperaci√≥n de errores con reintentos inteligentes
   */
  private async executeWithRetry<T>(
    operation: () => Promise<T>,
    maxRetries: number = 3,
    baseDelay: number = 1000,
    context: string = 'operaci√≥n'
  ): Promise<T> {
    let lastError: any;
    
    for (let attempt = 1; attempt <= maxRetries; attempt++) {
      try {
        console.log(`üîÑ [${context}] Intento ${attempt}/${maxRetries}`);
        const result = await operation();
        
        if (attempt > 1) {
          console.log(`‚úÖ [${context}] √âxito en intento ${attempt} despu√©s de ${attempt - 1} fallos`);
        }
        
        return result;
      } catch (error) {
        lastError = error;
        console.error(`‚ùå [${context}] Fallo en intento ${attempt}:`, error);
        
        // No reintentar en el √∫ltimo intento
        if (attempt === maxRetries) {
          console.error(`üî¥ [${context}] Todos los intentos fallaron. Error final:`, error);
          break;
        }
        
        // Calcular delay exponencial con jitter
        const delay = baseDelay * Math.pow(2, attempt - 1) + Math.random() * 1000;
        console.log(`‚è≥ [${context}] Esperando ${delay.toFixed(0)}ms antes del siguiente intento...`);
        
        await new Promise(resolve => setTimeout(resolve, delay));
      }
    }
    
    throw lastError;
  }

  /**
   * Valida la respuesta de OpenAI antes del procesamiento
   */
  private validateOpenAIResponse(response: string, questionId: string): boolean {
    if (!response || response.trim().length === 0) {
      console.error(`‚ùå [${questionId}] Respuesta vac√≠a de OpenAI`);
      return false;
    }
    
    if (response.length < 50) {
      console.error(`‚ùå [${questionId}] Respuesta demasiado corta (${response.length} caracteres): "${response}"`);
      return false;
    }
    
    // Verificar que contenga al menos algo que parezca JSON
    if (!response.includes('{') || !response.includes('}')) {
      console.error(`‚ùå [${questionId}] Respuesta no contiene JSON v√°lido`);
      return false;
    }
    
    // Verificar que no sea solo un mensaje de error
    const errorPatterns = [
      'i cannot',
      'i\'m unable',
      'i don\'t have access',
      'i cannot provide',
      'i\'m sorry',
      'error occurred',
      'something went wrong'
    ];
    
    const lowerResponse = response.toLowerCase();
    for (const pattern of errorPatterns) {
      if (lowerResponse.includes(pattern)) {
        console.error(`‚ùå [${questionId}] Respuesta contiene patr√≥n de error: "${pattern}"`);
        return false;
      }
    }
    
    console.log(`‚úÖ [${questionId}] Respuesta de OpenAI validada correctamente`);
    return true;
  }

  /**
   * Consolida menciones de marca con configuraci√≥n personalizada
   */
  /**
   * Consolida menciones de marca usando configuraci√≥n personalizada
   *
   * IMPORTANTE - ALCANCE DE LA COMPARATIVA:
   * Esta funci√≥n consolida las menciones de TODAS las preguntas del an√°lisis,
   * incluyendo tanto preguntas gen√©ricas como preguntas espec√≠ficas de marca.
   *
   * Ejemplo:
   * - Si una pregunta gen√©rica menciona "Mapfre" 3 veces
   * - Y una pregunta espec√≠fica de marca menciona "Mapfre" 2 veces
   * - El resultado consolidado mostrar√° "Mapfre" con 5 menciones totales
   *
   * Este enfoque permite tener una visi√≥n global de la presencia de cada marca
   * en todo el conjunto de respuestas generadas por la IA.
   *
   * @param analyses Array de an√°lisis de preguntas (incluye TODAS las preguntas)
   * @param configuration Configuraci√≥n con targetBrands y competitorBrands
   * @returns Objeto con arrays de targetBrands y competitors consolidados
   */
  private consolidateBrandMentionsWithConfiguration(analyses: QuestionAnalysis[], configuration: any): {
    targetBrands: BrandMention[];
    competitors: BrandMention[];
  } {
    const brandMap = new Map<string, BrandMention>();

    // Consolidar todas las menciones de TODAS las preguntas
    analyses.forEach(analysis => {
      analysis.brandMentions.forEach(mention => {
        const existing = brandMap.get(mention.brand);
        if (existing) {
          existing.frequency += mention.frequency;
          existing.evidence.push(...mention.evidence);
          existing.mentioned = existing.mentioned || mention.mentioned;
        } else {
          brandMap.set(mention.brand, { ...mention });
        }
      });
    });

    // Separar marcas objetivo y competidores usando la configuraci√≥n
    const targetBrands: BrandMention[] = [];
    const competitors: BrandMention[] = [];

    const configTargetBrands = configuration.targetBrands || (configuration.targetBrand ? [configuration.targetBrand] : TARGET_BRANDS);
    const configCompetitorBrands = configuration.competitorBrands || COMPETITOR_BRANDS;

    brandMap.forEach(mention => {
      if (configTargetBrands.includes(mention.brand as any)) {
        targetBrands.push(mention);
      } else if (configCompetitorBrands.includes(mention.brand as any)) {
        competitors.push(mention);
      }
    });

    return { targetBrands, competitors };
  }

  /**
   * Consolida menciones de marca de todos los an√°lisis
   *
   * IMPORTANTE - ALCANCE DE LA COMPARATIVA:
   * Esta funci√≥n consolida las menciones de TODAS las preguntas del an√°lisis,
   * incluyendo tanto preguntas gen√©ricas como preguntas espec√≠ficas de marca.
   *
   * Ejemplo:
   * - Si una pregunta gen√©rica menciona "Mapfre" 3 veces
   * - Y una pregunta espec√≠fica de marca menciona "Mapfre" 2 veces
   * - El resultado consolidado mostrar√° "Mapfre" con 5 menciones totales
   *
   * Este enfoque permite tener una visi√≥n global de la presencia de cada marca
   * en todo el conjunto de respuestas generadas por la IA.
   */
  private consolidateBrandMentions(analyses: QuestionAnalysis[]): {
    targetBrands: BrandMention[];
    competitors: BrandMention[];
  } {
    const brandMap = new Map<string, BrandMention>();

    // Consolidar todas las menciones
    analyses.forEach(analysis => {
      analysis.brandMentions.forEach(mention => {
        const existing = brandMap.get(mention.brand);
        if (existing) {
          existing.frequency += mention.frequency;
          existing.evidence.push(...mention.evidence);
          existing.mentioned = existing.mentioned || mention.mentioned;
        } else {
          brandMap.set(mention.brand, { ...mention });
        }
      });
    });

    // Separar marcas objetivo y competidores
    const targetBrands: BrandMention[] = [];
    const competitors: BrandMention[] = [];

    brandMap.forEach(mention => {
      if (TARGET_BRANDS.includes(mention.brand as any)) {
        targetBrands.push(mention);
      } else if (COMPETITOR_BRANDS.includes(mention.brand as any)) {
        competitors.push(mention);
      }
    });

    return { targetBrands, competitors };
  }

  /**
   * Consolida menciones de marca por tipo de pregunta
   *
   * Separa las menciones entre:
   * - Preguntas gen√©ricas: Aquellas que NO mencionan marcas espec√≠ficas en el texto de la pregunta
   * - Preguntas espec√≠ficas: Aquellas que S√ç mencionan marcas espec√≠ficas en el texto de la pregunta
   *
   * @param analyses Array de an√°lisis de preguntas
   * @param configuration Configuraci√≥n con targetBrands y competitorBrands
   * @returns Objeto con menciones separadas por tipo de pregunta
   */
  consolidateBrandMentionsByQuestionType(analyses: QuestionAnalysis[], configuration?: any): {
    all: {
      targetBrands: BrandMention[];
      competitors: BrandMention[];
    };
    generic: {
      targetBrands: BrandMention[];
      competitors: BrandMention[];
    };
    specific: {
      targetBrands: BrandMention[];
      competitors: BrandMention[];
    };
  } {
    // Determinar marcas objetivo y competidores de la configuraci√≥n
    const targetBrands = configuration?.targetBrands ||
                         (configuration?.targetBrand ? [configuration.targetBrand] : TARGET_BRANDS);
    const competitorBrands = configuration?.competitorBrands || COMPETITOR_BRANDS;
    const allBrands = [...targetBrands, ...competitorBrands];

    // Separar an√°lisis por tipo de pregunta
    const genericQuestions: QuestionAnalysis[] = [];
    const specificQuestions: QuestionAnalysis[] = [];

    analyses.forEach(analysis => {
      // Verificar si la pregunta menciona alguna marca
      const questionLower = analysis.question.toLowerCase();
      const mentionsBrand = allBrands.some(brand =>
        questionLower.includes(brand.toLowerCase())
      );

      if (mentionsBrand) {
        specificQuestions.push(analysis);
      } else {
        genericQuestions.push(analysis);
      }
    });

    // Consolidar menciones por tipo
    const allMentions = configuration ?
      this.consolidateBrandMentionsWithConfiguration(analyses, configuration) :
      this.consolidateBrandMentions(analyses);

    const genericMentions = configuration ?
      this.consolidateBrandMentionsWithConfiguration(genericQuestions, configuration) :
      this.consolidateBrandMentions(genericQuestions);

    const specificMentions = configuration ?
      this.consolidateBrandMentionsWithConfiguration(specificQuestions, configuration) :
      this.consolidateBrandMentions(specificQuestions);

    return {
      all: allMentions,
      generic: genericMentions,
      specific: specificMentions
    };
  }

  /**
   * Genera un resumen ejecutivo consolidado de todas las preguntas analizadas
   */
  private generateExecutiveSummary(analysis: AnalysisResult): string {
    let summary = '';

    // Estad√≠sticas generales
    const totalQuestions = analysis.questions.length;
    const avgConfidence = analysis.overallConfidence;

    // An√°lisis de sentimiento general
    const sentimentCounts = {
      positive: 0,
      neutral: 0,
      negative: 0
    };

    analysis.questions.forEach(q => {
      if (q.sentiment === 'positive') sentimentCounts.positive++;
      else if (q.sentiment === 'negative') sentimentCounts.negative++;
      else sentimentCounts.neutral++;
    });

    // Menciones de marcas objetivo
    const targetBrandsMentioned = analysis.brandSummary.targetBrands.filter(b => b.mentioned);
    const competitorsMentioned = analysis.brandSummary.competitors.filter(b => b.mentioned);

    // Categor√≠as analizadas
    const categories = [...new Set(analysis.questions.map(q => q.category))];

    summary += `### üìä Visi√≥n General del An√°lisis\n\n`;
    summary += `Se realiz√≥ un an√°lisis exhaustivo de **${totalQuestions} preguntas** distribuidas en ${categories.length} categor√≠as diferentes. `;
    summary += `El nivel de confianza promedio del an√°lisis fue del **${(avgConfidence * 100).toFixed(1)}%**, `;
    summary += `procesando ${analysis.totalSources} fuentes de informaci√≥n.\n\n`;

    summary += `### üéØ Hallazgos Clave de Menciones de Marca\n\n`;

    if (targetBrandsMentioned.length > 0) {
      summary += `**Marcas Objetivo:**\n`;
      targetBrandsMentioned.forEach(brand => {
        const sentimentEmoji = brand.context === 'positive' ? '‚úÖ' : brand.context === 'negative' ? '‚ùå' : '‚ö™';
        summary += `- ${sentimentEmoji} **${brand.brand}**: ${brand.frequency} menciones (contexto ${brand.context})\n`;
      });
      summary += `\n`;
    } else {
      summary += `**Marcas Objetivo:** No se encontraron menciones significativas en las respuestas analizadas.\n\n`;
    }

    if (competitorsMentioned.length > 0) {
      summary += `**Principales Competidores Mencionados:**\n`;
      const topCompetitors = competitorsMentioned
        .sort((a, b) => b.frequency - a.frequency)
        .slice(0, 5);

      topCompetitors.forEach(brand => {
        const sentimentEmoji = brand.context === 'positive' ? '‚úÖ' : brand.context === 'negative' ? '‚ùå' : '‚ö™';
        summary += `- ${sentimentEmoji} **${brand.brand}**: ${brand.frequency} menciones (contexto ${brand.context})\n`;
      });
      summary += `\n`;
    }

    summary += `### üòä An√°lisis de Sentimiento Global\n\n`;
    summary += `- **Positivo:** ${sentimentCounts.positive} preguntas (${((sentimentCounts.positive/totalQuestions)*100).toFixed(1)}%)\n`;
    summary += `- **Neutral:** ${sentimentCounts.neutral} preguntas (${((sentimentCounts.neutral/totalQuestions)*100).toFixed(1)}%)\n`;
    summary += `- **Negativo:** ${sentimentCounts.negative} preguntas (${((sentimentCounts.negative/totalQuestions)*100).toFixed(1)}%)\n\n`;

    summary += `### üìÅ Categor√≠as Analizadas\n\n`;
    categories.forEach(category => {
      const questionsInCategory = analysis.questions.filter(q => q.category === category).length;
      summary += `- **${category}**: ${questionsInCategory} pregunta(s)\n`;
    });
    summary += `\n`;

    summary += `### üîç Conclusiones Principales\n\n`;

    if (targetBrandsMentioned.length === 0) {
      summary += `‚ö†Ô∏è **Visibilidad limitada**: Las marcas objetivo no aparecen mencionadas de forma significativa en las respuestas de IA generativa analizadas. `;
      summary += `Esto sugiere una oportunidad de mejora en la presencia digital y SEO para influir en las respuestas de modelos de IA.\n\n`;
    } else {
      const positiveTargetMentions = targetBrandsMentioned.filter(b => b.context === 'positive').length;
      const totalTargetMentions = targetBrandsMentioned.reduce((sum, b) => sum + b.frequency, 0);

      if (positiveTargetMentions > 0) {
        summary += `‚úÖ **Presencia positiva**: Se detectaron ${totalTargetMentions} menciones de marcas objetivo, `;
        summary += `con ${positiveTargetMentions} marca(s) mencionadas en contexto positivo.\n\n`;
      } else {
        summary += `‚ö†Ô∏è **Atenci√≥n requerida**: Aunque las marcas objetivo fueron mencionadas ${totalTargetMentions} veces, `;
        summary += `el contexto no fue predominantemente positivo.\n\n`;
      }
    }

    if (competitorsMentioned.length > 0) {
      const topCompetitor = competitorsMentioned.sort((a, b) => b.frequency - a.frequency)[0];
      summary += `üèÜ **Competidor m√°s mencionado**: ${topCompetitor.brand} con ${topCompetitor.frequency} menciones `;
      summary += `en contexto ${topCompetitor.context}.\n\n`;
    }

    return summary;
  }

  /**
   * Genera informe en formato Markdown
   */
  generateMarkdownReport(analysis: AnalysisResult, configuration?: any): string {
    const date = new Date(analysis.timestamp).toLocaleDateString('es-ES', {
      timeZone: 'Europe/Madrid',
      year: 'numeric',
      month: 'long',
      day: 'numeric',
      hour: '2-digit',
      minute: '2-digit'
    });

    let markdown = `# Informe de An√°lisis de Presencia en IA Generativa\n\n`;
    markdown += `**Fecha:** ${date}\n`;
    markdown += `**ID de An√°lisis:** ${analysis.analysisId}\n`;
    markdown += `**Categor√≠as analizadas:** ${analysis.categories.join(', ')}\n`;
    markdown += `**Confianza general:** ${(analysis.overallConfidence * 100).toFixed(1)}%\n\n`;

    // Resumen ejecutivo consolidado
    markdown += `## üìã Resumen Ejecutivo\n\n`;
    markdown += this.generateExecutiveSummary(analysis);
    markdown += `\n---\n\n`;

    // Comparativas de menciones de marca
    if (analysis.brandSummaryByType) {
      markdown += `## üìä Comparativa de Menciones de Marca\n\n`;

      // Secci√≥n de preguntas gen√©ricas
      markdown += `### üìã Solo Preguntas Gen√©ricas\n`;
      markdown += `*Menciones en preguntas que NO incluyen nombres de marca espec√≠ficos*\n\n`;

      if (analysis.brandSummaryByType.generic.targetBrands.length > 0) {
        markdown += `#### Marcas Objetivo\n`;
        analysis.brandSummaryByType.generic.targetBrands
          .filter(b => b.mentioned && b.frequency > 0)
          .sort((a, b) => b.frequency - a.frequency)
          .forEach(brand => {
            const sentiment = brand.context === 'positive' ? '‚úÖ' : brand.context === 'negative' ? '‚ùå' : '‚ö™';
            markdown += `- ${sentiment} **${brand.brand}**: ${brand.frequency} menciones\n`;
          });
        markdown += `\n`;
      }

      if (analysis.brandSummaryByType.generic.competitors.length > 0) {
        markdown += `#### Competidores\n`;
        analysis.brandSummaryByType.generic.competitors
          .filter(b => b.mentioned && b.frequency > 0)
          .sort((a, b) => b.frequency - a.frequency)
          .slice(0, 5)
          .forEach(brand => {
            const sentiment = brand.context === 'positive' ? '‚úÖ' : brand.context === 'negative' ? '‚ùå' : '‚ö™';
            markdown += `- ${sentiment} **${brand.brand}**: ${brand.frequency} menciones\n`;
          });
        markdown += `\n`;
      }

      // Secci√≥n de preguntas espec√≠ficas
      markdown += `### üéØ Solo Preguntas Espec√≠ficas de Marca\n`;
      markdown += `*Menciones en preguntas que S√ç incluyen nombres de marca espec√≠ficos*\n\n`;

      if (analysis.brandSummaryByType.specific.targetBrands.length > 0) {
        markdown += `#### Marcas Objetivo\n`;
        analysis.brandSummaryByType.specific.targetBrands
          .filter(b => b.mentioned && b.frequency > 0)
          .sort((a, b) => b.frequency - a.frequency)
          .forEach(brand => {
            const sentiment = brand.context === 'positive' ? '‚úÖ' : brand.context === 'negative' ? '‚ùå' : '‚ö™';
            markdown += `- ${sentiment} **${brand.brand}**: ${brand.frequency} menciones\n`;
          });
        markdown += `\n`;
      }

      if (analysis.brandSummaryByType.specific.competitors.length > 0) {
        markdown += `#### Competidores\n`;
        analysis.brandSummaryByType.specific.competitors
          .filter(b => b.mentioned && b.frequency > 0)
          .sort((a, b) => b.frequency - a.frequency)
          .slice(0, 5)
          .forEach(brand => {
            const sentiment = brand.context === 'positive' ? '‚úÖ' : brand.context === 'negative' ? '‚ùå' : '‚ö™';
            markdown += `- ${sentiment} **${brand.brand}**: ${brand.frequency} menciones\n`;
          });
        markdown += `\n`;
      }

      markdown += `---\n\n`;
    }

    // Menciones de marcas objetivo (comparativa total)
    if (analysis.brandSummary.targetBrands.length > 0) {
      const targetBrandsLabel = configuration?.targetBrands?.join(', ') ||
                                configuration?.targetBrand ||
                                'Marcas Objetivo';
      markdown += `## üéØ Comparativa Total - ${targetBrandsLabel}\n`;
      markdown += `*Incluye TODAS las preguntas (gen√©ricas + espec√≠ficas)*\n\n`;

      analysis.brandSummary.targetBrands.forEach(brand => {
        const sentiment = brand.context === 'positive' ? '‚úÖ' : brand.context === 'negative' ? '‚ùå' : '‚ö™';
        markdown += `### ${sentiment} ${brand.brand}\n`;
        markdown += `- **Mencionada:** ${brand.mentioned ? 'S√≠' : 'No'}\n`;
        markdown += `- **Frecuencia Total:** ${brand.frequency} menciones\n`;
        markdown += `- **Contexto:** ${brand.context}\n`;
        if (brand.evidence.length > 0) {
          markdown += `- **Evidencia:**\n`;
          brand.evidence.slice(0, 3).forEach(evidence => {
            markdown += `  - "${evidence}"\n`;
          });
        }
        markdown += `\n`;
      });
    }

    // An√°lisis por pregunta
    markdown += `## üìù An√°lisis Detallado por Pregunta\n\n`;
    analysis.questions.forEach((q, index) => {
      markdown += `### ${index + 1}. ${q.question}\n\n`;
      markdown += `**Categor√≠a:** ${q.category}\n`;
      markdown += `**Confianza:** ${(q.confidenceScore * 100).toFixed(1)}%\n`;
      markdown += `**Sentimiento general:** ${q.sentiment}\n\n`;

      // An√°lisis resumido
      markdown += `#### üìä An√°lisis\n\n`;
      markdown += `${q.summary}\n\n`;

      // Contenido completo extra√≠do del LLM - SIEMPRE mostrar
      if (q.sources.length > 0) {
        const source = q.sources[0];
        const fullContent = source.fullContent || source.snippet || 'No hay contenido disponible';
        markdown += `#### ü§ñ Respuesta Completa del LLM (${source.domain})\n\n`;
        markdown += `\`\`\`\n${fullContent}\n\`\`\`\n\n`;
      } else {
        markdown += `#### ü§ñ Respuesta Completa del LLM\n\n`;
        markdown += `\`\`\`\nNo hay fuentes disponibles para esta pregunta\n\`\`\`\n\n`;
      }

      // Menciones de marca en esta pregunta
      if (q.brandMentions && q.brandMentions.length > 0) {
        const mentionedBrands = q.brandMentions.filter(b => b.mentioned && b.frequency > 0);
        if (mentionedBrands.length > 0) {
          markdown += `#### üè¢ Marcas Mencionadas\n\n`;
          mentionedBrands.forEach(brand => {
            const sentimentEmoji = brand.context === 'positive' ? '‚úÖ' : brand.context === 'negative' ? '‚ùå' : '‚ö™';
            markdown += `- ${sentimentEmoji} **${brand.brand}** (${brand.frequency} menci√≥n/es - contexto ${brand.context})\n`;
            if (brand.evidence && brand.evidence.length > 0) {
              markdown += `  - Evidencia: "${brand.evidence[0]}"\n`;
            }
          });
          markdown += `\n`;
        }
      }

      // Fuentes consultadas
      if (q.sources.length > 0) {
        markdown += `#### üìö Fuentes Consultadas\n\n`;
        q.sources.forEach(source => {
          const priority = source.isPriority ? ' ‚≠ê' : '';
          markdown += `- **Fuente:** ${source.domain}${priority}\n`;
          markdown += `- **T√≠tulo:** ${source.title}\n`;
          if (source.url !== 'generative-ai-response') {
            markdown += `- **URL:** ${source.url}\n`;
          }
        });
        markdown += `\n`;
      }

      markdown += `---\n\n`;
    });

    return markdown;
  }

  /**
   * Genera informe en formato JSON estructurado
   */
  generateJSONReport(analysis: AnalysisResult): object {
    const baseReport = {
      metadata: {
        analysisId: analysis.analysisId,
        timestamp: analysis.timestamp,
        timezone: "Europe/Madrid",
        locale: "es-ES",
        categories: analysis.categories,
        totalQuestions: analysis.questions.length,
        overallConfidence: analysis.overallConfidence
      },
      metrics: {
        totalSources: analysis.totalSources,
        prioritySources: analysis.prioritySources,
        prioritySourcesPercentage: analysis.totalSources > 0 ?
          (analysis.prioritySources / analysis.totalSources * 100) : 0
      },
      brandAnalysis: {
        targetBrands: analysis.brandSummary.targetBrands.map(brand => ({
          name: brand.brand,
          mentioned: brand.mentioned,
          frequency: brand.frequency,
          sentiment: brand.context,
          evidence: brand.evidence,
          relevanceScore: brand.frequency > 0 ? Math.min(brand.frequency / 10, 1) : 0
        })),
        competitors: analysis.brandSummary.competitors.map(brand => ({
          name: brand.brand,
          mentioned: brand.mentioned,
          frequency: brand.frequency,
          sentiment: brand.context,
          evidence: brand.evidence,
          relevanceScore: brand.frequency > 0 ? Math.min(brand.frequency / 10, 1) : 0
        }))
      },
      detailedAnalysis: analysis.questions.map(q => ({
        questionId: q.questionId,
        question: q.question,
        category: q.category,
        summary: q.summary,
        sentiment: q.sentiment,
        confidenceScore: q.confidenceScore,
        sources: q.sources.map(source => ({
          url: source.url,
          title: source.title,
          snippet: source.snippet,
          fullContent: source.fullContent, // Incluir contenido completo del LLM
          domain: source.domain,
          isPriority: source.isPriority,
          trustScore: source.isPriority ? 0.9 : 0.6
        })),
        brandMentions: q.brandMentions
      }))
    };

    // Agregar comparativas por tipo si est√°n disponibles
    if (analysis.brandSummaryByType) {
      (baseReport as any).brandAnalysisByType = {
        generic: {
          description: "Menciones en preguntas que NO incluyen nombres de marca espec√≠ficos",
          targetBrands: analysis.brandSummaryByType.generic.targetBrands.map(brand => ({
            name: brand.brand,
            mentioned: brand.mentioned,
            frequency: brand.frequency,
            sentiment: brand.context,
            evidence: brand.evidence
          })),
          competitors: analysis.brandSummaryByType.generic.competitors.map(brand => ({
            name: brand.brand,
            mentioned: brand.mentioned,
            frequency: brand.frequency,
            sentiment: brand.context,
            evidence: brand.evidence
          }))
        },
        specific: {
          description: "Menciones en preguntas que S√ç incluyen nombres de marca espec√≠ficos",
          targetBrands: analysis.brandSummaryByType.specific.targetBrands.map(brand => ({
            name: brand.brand,
            mentioned: brand.mentioned,
            frequency: brand.frequency,
            sentiment: brand.context,
            evidence: brand.evidence
          })),
          competitors: analysis.brandSummaryByType.specific.competitors.map(brand => ({
            name: brand.brand,
            mentioned: brand.mentioned,
            frequency: brand.frequency,
            sentiment: brand.context,
            evidence: brand.evidence
          }))
        },
        all: {
          description: "Menciones en TODAS las preguntas (gen√©ricas + espec√≠ficas)",
          targetBrands: analysis.brandSummaryByType.all.targetBrands.map(brand => ({
            name: brand.brand,
            mentioned: brand.mentioned,
            frequency: brand.frequency,
            sentiment: brand.context,
            evidence: brand.evidence
          })),
          competitors: analysis.brandSummaryByType.all.competitors.map(brand => ({
            name: brand.brand,
            mentioned: brand.mentioned,
            frequency: brand.frequency,
            sentiment: brand.context,
            evidence: brand.evidence
          }))
        }
      };
    }

    return baseReport;
  }

  /**
   * Genera informe en formato tabla CSV
   */
  generateTableReport(analysis: AnalysisResult, configuration?: any): string {
    // Cabecera del CSV
    let csv = 'Pregunta,Categor√≠a,Marcas Mencionadas,Confianza (%),Sentimiento\n';

    // Procesar cada pregunta
    analysis.questions.forEach(q => {
      // Extraer las marcas mencionadas
      const mentionedBrands = q.brandMentions
        ?.filter(b => b.mentioned && b.frequency > 0)
        .map(b => `${b.brand} (${b.context})`)
        .join('; ') || 'Ninguna';

      // Formatear la pregunta para CSV (escapar comillas y comas)
      const questionText = `"${q.question.replace(/"/g, '""')}"`;
      const category = `"${q.category}"`;
      const brands = `"${mentionedBrands}"`;
      const confidence = (q.confidenceScore * 100).toFixed(1);
      const sentiment = q.sentiment;

      // Agregar fila
      csv += `${questionText},${category},${brands},${confidence},${sentiment}\n`;
    });

    return csv;
  }

  /**
   * Ejecuta an√°lisis con m√∫ltiples modelos de IA (simulados)
   */
  async executeMultiModelAnalysis(questions: any[], configuration: any): Promise<AnalysisResult> {
  const startTime = Date.now();
  const analysisId = `multimodel_analysis_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`;
  const timestamp = new Date().toISOString();

  // Solo usar ChatGPT por defecto si no se especifican otros modelos
  const aiModels = configuration.aiModels || ['chatgpt'];

  console.log(`üöÄ Iniciando an√°lisis multi-modelo con ID: ${analysisId}`);
  console.log(`ü§ñ Modelos configurados: ${aiModels.join(', ')}`);

  const results: QuestionAnalysis[] = [];
  const errors: string[] = [];
  
  try {
    // Procesar cada pregunta con m√∫ltiples modelos
    for (const questionData of questions) {
      console.log(`üìù Procesando pregunta: ${questionData.question}`);
      
      const multiModelAnalysis = await this.analyzeQuestionWithMultipleModels(questionData, configuration);
      results.push(multiModelAnalysis);
    }
  
    // Calcular m√©tricas generales
    const totalSources = results.reduce((sum, q) => sum + q.sources.length, 0);
    const prioritySources = results.reduce((sum, q) => 
      sum + q.sources.filter(s => s.isPriority).length, 0
    );
    
    const overallConfidence = results.reduce((sum, q) => sum + q.confidenceScore, 0) / results.length;
  
    // Consolidar menciones de marca con an√°lisis competitivo
    const consolidatedMentions = this.consolidateBrandMentionsWithCompetitiveAnalysis(results, configuration);

    // Nuevo: Consolidar por tipo de pregunta
    const mentionsByType = this.consolidateBrandMentionsByQuestionType(results, configuration);

    const endTime = Date.now();
    console.log(`‚úÖ An√°lisis multi-modelo completado en ${endTime - startTime}ms`);
    console.log(`   üìä Preguntas procesadas: ${results.length}`);
    console.log(`   üè∑Ô∏è Menciones de marca consolidadas: ${consolidatedMentions.targetBrands.length + consolidatedMentions.competitors.length}`);
    console.log(`   üìà Confianza general: ${(overallConfidence * 100).toFixed(1)}%`);
  
    return {
      analysisId,
      timestamp,
      categories: [],
      questions: results,
      overallConfidence,
      totalSources,
      prioritySources,
      brandSummary: consolidatedMentions,
      brandSummaryByType: mentionsByType
    };
  
  } catch (error) {
    console.error('üî¥ Error en an√°lisis multi-modelo:', error);
    throw error;
  }
}

/**
 * Analiza una pregunta con m√∫ltiples modelos de IA simulados
 */
private async analyzeQuestionWithMultipleModels(questionData: any, configuration: any): Promise<QuestionAnalysis> {
  const questionId = questionData.id || `q_${Date.now()}`;
  // Solo usar ChatGPT por defecto si no se especifican otros modelos
  const aiModels: AIModelPersona[] = configuration.aiModels || ['chatgpt'];

  console.log(`ü§ñ [${questionId}] Analizando con modelos: ${aiModels.join(', ')}`);

  const multiModelResults: MultiModelAnalysis[] = [];
  const failedModels: string[] = [];

  // Analizar con cada modelo de IA
  for (const modelPersona of aiModels) {
    try {
      console.log(`üîÑ [${questionId}] Intentando an√°lisis con ${modelPersona}...`);
      const modelAnalysis = await this.analyzeWithAIPersona(questionData, modelPersona, configuration);
      multiModelResults.push(modelAnalysis);
      console.log(`‚úÖ [${questionId}] An√°lisis completado con ${modelPersona}`);
    } catch (error) {
      console.error(`üî¥ [${questionId}] Error con modelo ${modelPersona}:`, error);
      failedModels.push(modelPersona);
      console.log(`‚ö†Ô∏è [${questionId}] Modelo ${modelPersona} omitido, continuando con otros modelos...`);
    }
  }

  // Log de resultados
  if (multiModelResults.length > 0) {
    console.log(`‚úÖ [${questionId}] ${multiModelResults.length} de ${aiModels.length} modelos completados exitosamente`);
  }

  if (failedModels.length > 0) {
    console.log(`‚ö†Ô∏è [${questionId}] Modelos que fallaron: ${failedModels.join(', ')}`);
  }

  // Consolidar resultados de m√∫ltiples modelos (maneja gracefully si est√° vac√≠o)
  return this.consolidateMultiModelResults(questionData, multiModelResults, configuration);
}

/**
 * Analiza con una persona de IA espec√≠fica
 */
private async analyzeWithAIPersona(questionData: any, modelPersona: AIModelPersona, configuration: any): Promise<MultiModelAnalysis> {
  const questionId = questionData.id || `q_${Date.now()}`;
  
  // PASO 1: Generar respuesta con la persona del modelo espec√≠fico
  const generativePrompt = this.buildPersonaGenerativePrompt(questionData.question, modelPersona, configuration);

  const generativeResponse = await this.client.chat.completions.create({
    model: this.GENERATION_MODEL, // Usar modelo PRINCIPAL para generar respuestas de calidad
    messages: [{ role: 'user', content: generativePrompt }],
    temperature: this.getModelTemperature(modelPersona),
    max_tokens: configuration.maxTokens || 2000,
  });

  const generatedContent = generativeResponse.choices[0]?.message?.content || '';

  // PASO 2: Analizar la respuesta para menciones de marca con an√°lisis contextual
  const analysisPrompt = this.buildEnhancedAnalysisPrompt(questionData.question, generatedContent, modelPersona, configuration);

  const analysisResponse = await this.client.chat.completions.create({
    model: this.ANALYSIS_MODEL, // Usar modelo ECON√ìMICO para analizar menciones (ahorro de costos)
    messages: [{ role: 'user', content: analysisPrompt }],
    temperature: 0.1,
    max_tokens: 2500,
  });

  const analysisResult = analysisResponse.choices[0]?.message?.content || '';
  
  // Parsear resultados con an√°lisis contextual
   return this.parseEnhancedAnalysisResponse(questionData, generatedContent, analysisResult, modelPersona, configuration);
 }

  /**
   * Construye prompt para generar respuesta con persona espec√≠fica de IA
   */
  private buildPersonaGenerativePrompt(question: string, modelPersona: AIModelPersona, configuration: any): string {
    const targetBrands = configuration.targetBrands || configuration.targetBrand ? [configuration.targetBrand] : TARGET_BRANDS;
    const competitors = configuration.competitorBrands || COMPETITOR_BRANDS;
    
    const personaInstructions = this.getPersonaInstructions(modelPersona);
    
    return `${personaInstructions}

Responde a la siguiente pregunta de manera natural y √∫til:

"${question}"

Marcas objetivo a considerar: ${targetBrands.join(', ')}
Competidores principales: ${competitors.join(', ')}

Proporciona una respuesta completa, informativa y natural de 200-400 palabras. Puedes mencionar marcas cuando sea apropiado y √∫til para el usuario.`;
  }

  /**
   * Obtiene instrucciones espec√≠ficas para cada persona de IA
   */
  private getPersonaInstructions(modelPersona: AIModelPersona): string {
    switch (modelPersona) {
      case 'chatgpt':
        return `Act√∫a como ChatGPT: S√© conversacional, equilibrado y estructurado. Proporciona informaci√≥n pr√°ctica y bien organizada. Usa un tono profesional pero accesible.`;
      
      case 'claude':
        return `Act√∫a como Claude (Anthropic): S√© anal√≠tico, detallado y cuidadoso. Proporciona explicaciones profundas y considera m√∫ltiples perspectivas. Usa un tono reflexivo y preciso.`;
      
      case 'gemini':
        return `Act√∫a como Gemini (Google): S√© conciso, directo y orientado a datos. Proporciona informaci√≥n factual y comparaciones claras. Usa un tono eficiente y basado en hechos.`;
      
      case 'perplexity':
        return `Act√∫a como Perplexity: S√© investigativo y basado en fuentes. Proporciona informaci√≥n actualizada con referencias impl√≠citas. Usa un tono acad√©mico pero accesible.`;
      
      default:
        return `Proporciona una respuesta √∫til e informativa sobre el tema consultado en Espa√±a.`;
    }
  }

  /**
   * Obtiene temperatura espec√≠fica para cada modelo
   */
  private getModelTemperature(modelPersona: AIModelPersona): number {
    switch (modelPersona) {
      case 'chatgpt': return 0.7;
      case 'claude': return 0.5;
      case 'gemini': return 0.3;
      case 'perplexity': return 0.4;
      default: return 0.6;
    }
  }

  /**
   * Construye prompt mejorado para an√°lisis con sentimientos y contexto
   */
  private buildEnhancedAnalysisPrompt(originalQuestion: string, generatedContent: string, modelPersona: AIModelPersona, configuration: any): string {
    const targetBrands = configuration.targetBrands || configuration.targetBrand ? [configuration.targetBrand] : TARGET_BRANDS;
    const competitors = configuration.competitorBrands || COMPETITOR_BRANDS;
    
    return `Analiza la siguiente respuesta de IA (generada por ${modelPersona}) para detectar menciones de marca y realizar un an√°lisis contextual avanzado:

PREGUNTA ORIGINAL: "${originalQuestion}"

RESPUESTA DE IA A ANALIZAR:
"${generatedContent}"

MARCAS OBJETIVO: ${targetBrands.join(', ')}
COMPETIDORES: ${competitors.join(', ')}

Realiza un an√°lisis EXHAUSTIVO y responde en formato JSON con esta estructura exacta:

{
  "overallSentiment": "very_positive|positive|neutral|negative|very_negative",
  "contextualInsights": "An√°lisis detallado del contexto y tono general de la respuesta",
  "brandMentions": [
    {
      "brand": "Nombre exacto de la marca",
      "mentioned": true/false,
      "frequency": n√∫mero_de_menciones,
      "context": "positive|negative|neutral",
      "evidence": ["cita textual 1", "cita textual 2"],
      "detailedSentiment": "very_positive|positive|neutral|negative|very_negative",
      "contextualAnalysis": {
        "sentiment": "very_positive|positive|neutral|negative|very_negative",
        "confidence": 0.0-1.0,
        "reasoning": "Explicaci√≥n del an√°lisis de sentimiento",
        "competitivePosition": "leader|follower|neutral|not_mentioned",
        "contextType": "comparison|standalone|recommendation|review|news"
      },
      "competitiveComparison": {
        "comparedWith": ["marca1", "marca2"],
        "position": "better|worse|equal|not_compared",
        "reasoning": "Explicaci√≥n de la comparaci√≥n competitiva"
      }
    }
  ],
  "competitiveAnalysis": {
    "targetBrandPosition": "An√°lisis de la posici√≥n de las marcas objetivo",
    "competitorComparisons": [
      {
        "competitor": "Nombre del competidor",
        "comparison": "Descripci√≥n de la comparaci√≥n",
        "advantage": "target|competitor|neutral"
      }
    ]
  },
  "confidenceScore": 0.7-0.95
}

Responde √öNICAMENTE con el JSON v√°lido, sin texto adicional.`;
  }

  /**
   * Parsea respuesta mejorada con an√°lisis contextual
   */
  private parseEnhancedAnalysisResponse(questionData: any, generatedContent: string, analysisResponse: string, modelPersona: AIModelPersona, configuration: any): MultiModelAnalysis {
    try {
      const cleanedResponse = this.cleanJSONResponse(analysisResponse);
      const parsed = JSON.parse(cleanedResponse);
      
      return {
        modelPersona,
        response: generatedContent,
        brandMentions: parsed.brandMentions || [],
        overallSentiment: parsed.overallSentiment || 'neutral',
        contextualAnalysis: parsed.brandMentions?.map((brand: any) => brand.contextualAnalysis).filter(Boolean) || [],
        confidenceScore: parsed.confidenceScore || 0.75
      };
    } catch (error) {
      console.error(`üî¥ Error parseando respuesta mejorada para ${modelPersona}:`, error);
      return {
        modelPersona,
        response: generatedContent,
        brandMentions: [],
        overallSentiment: 'neutral',
        contextualAnalysis: [],
        confidenceScore: 0.5
      };
    }
  }

  /**
   * Consolida resultados de m√∫ltiples modelos
   */
  private consolidateMultiModelResults(questionData: any, multiModelResults: MultiModelAnalysis[], configuration: any): QuestionAnalysis {
    if (multiModelResults.length === 0) {
      console.warn(`‚ö†Ô∏è [${questionData.id}] No se pudo completar el an√°lisis con ning√∫n modelo, retornando an√°lisis de error`);
      return this.createErrorAnalysis(questionData);
    }

    console.log(`üìä [${questionData.id}] Consolidando resultados de ${multiModelResults.length} modelo(s)`);


    // Consolidar menciones de marca de todos los modelos
    const allBrandMentions: BrandMention[] = [];
    const brandMap = new Map<string, BrandMention>();

    multiModelResults.forEach(modelResult => {
      modelResult.brandMentions.forEach(mention => {
        const key = mention.brand.toLowerCase();
        if (brandMap.has(key)) {
          const existing = brandMap.get(key)!;
          existing.frequency += mention.frequency;
          existing.evidence.push(...mention.evidence);
          if (mention.mentioned) existing.mentioned = true;
        } else {
          brandMap.set(key, { ...mention });
        }
      });
    });

    // Calcular sentimiento general y confianza promedio
    const overallSentiments = multiModelResults.map(r => r.overallSentiment);
    const avgConfidence = multiModelResults.reduce((sum, r) => sum + r.confidenceScore, 0) / multiModelResults.length;

    // Crear an√°lisis competitivo consolidado
    const competitiveAnalysis = this.createCompetitiveAnalysis(multiModelResults, configuration);

    // Consolidar todas las respuestas en fullContent
    const allResponses = multiModelResults.map(r =>
      `=== ${r.modelPersona.toUpperCase()} ===\n\n${r.response}\n\n`
    ).join('\n');

    return {
      questionId: questionData.id,
      question: questionData.question,
      category: questionData.category || 'general',
      summary: `An√°lisis multi-modelo (${multiModelResults.map(r => r.modelPersona).join(', ')}) de respuestas de IA`,
      sources: [{
        url: 'ai-generated',
        title: 'Respuestas generadas por IA',
        snippet: multiModelResults[0]?.response.substring(0, 2000) + '...',
        domain: 'ai-models',
        isPriority: true,
        fullContent: allResponses // Guardar todas las respuestas completas
      }],
      brandMentions: Array.from(brandMap.values()),
      sentiment: this.calculateOverallSentiment(overallSentiments),
      confidenceScore: avgConfidence,
      multiModelAnalysis: multiModelResults,
      detailedSentiment: this.calculateDetailedSentiment(overallSentiments),
      contextualInsights: this.generateContextualInsights(multiModelResults),
      competitiveAnalysis
    };
  }

  /**
   * Crea an√°lisis competitivo basado en m√∫ltiples modelos
   */
  private createCompetitiveAnalysis(multiModelResults: MultiModelAnalysis[], configuration: any): any {
    const targetBrands = configuration.targetBrands || (configuration.targetBrand ? [configuration.targetBrand] : TARGET_BRANDS);
    const competitors = configuration.competitorBrands || COMPETITOR_BRANDS;

    const competitorComparisons: any[] = [];
    
    // Analizar menciones de competidores
    competitors.forEach(competitor => {
      const mentions = multiModelResults.flatMap(r => 
        r.brandMentions.filter(m => m.brand.toLowerCase().includes(competitor.toLowerCase()))
      );
      
      if (mentions.length > 0) {
        const avgSentiment = mentions.reduce((sum, m) => {
          const sentimentScore = this.sentimentToScore(m.context as SentimentType);
          return sum + sentimentScore;
        }, 0) / mentions.length;

        competitorComparisons.push({
          competitor,
          comparison: `Mencionado ${mentions.length} veces con sentimiento promedio ${avgSentiment.toFixed(2)}`,
          advantage: avgSentiment > 0 ? 'competitor' : avgSentiment < 0 ? 'target' : 'neutral'
        });
      }
    });

    return {
      targetBrandPosition: `An√°lisis basado en ${multiModelResults.length} modelos de IA diferentes`,
      competitorComparisons
    };
  }

  /**
   * Consolida menciones de marca con an√°lisis competitivo
   */
  private consolidateBrandMentionsWithCompetitiveAnalysis(analyses: QuestionAnalysis[], configuration: any): {
    targetBrands: BrandMention[];
    competitors: BrandMention[];
  } {
    const targetBrands = configuration.targetBrands || (configuration.targetBrand ? [configuration.targetBrand] : TARGET_BRANDS);
    const competitors = configuration.competitorBrands || COMPETITOR_BRANDS;

    const targetMap = new Map<string, BrandMention>();
    const competitorMap = new Map<string, BrandMention>();

    // Consolidar menciones de todas las preguntas
    analyses.forEach(analysis => {
      analysis.brandMentions.forEach(mention => {
        const brandLower = mention.brand.toLowerCase();
        const isTarget = targetBrands.some((brand: string) => brandLower.includes(brand.toLowerCase()));
        const map = isTarget ? targetMap : competitorMap;
        
        if (map.has(brandLower)) {
          const existing = map.get(brandLower)!;
          existing.frequency += mention.frequency;
          existing.evidence.push(...mention.evidence);
          if (mention.mentioned) existing.mentioned = true;
        } else {
          map.set(brandLower, { ...mention });
        }
      });
    });

    return {
      targetBrands: Array.from(targetMap.values()),
      competitors: Array.from(competitorMap.values())
    };
  }

  /**
   * Calcula sentimiento general basado en m√∫ltiples sentimientos
   */
  private calculateOverallSentiment(sentiments: DetailedSentiment[]): SentimentType {
    const sentimentScores = sentiments.map(s => this.detailedSentimentToScore(s));
    const avgScore = sentimentScores.reduce((sum, score) => sum + score, 0) / sentimentScores.length;
    
    if (avgScore > 0.3) return 'positive';
    if (avgScore < -0.3) return 'negative';
    return 'neutral';
  }

  /**
   * Calcula sentimiento detallado basado en m√∫ltiples sentimientos
   */
  private calculateDetailedSentiment(sentiments: DetailedSentiment[]): DetailedSentiment {
    const sentimentScores = sentiments.map(s => this.detailedSentimentToScore(s));
    const avgScore = sentimentScores.reduce((sum, score) => sum + score, 0) / sentimentScores.length;
    
    if (avgScore > 0.6) return 'very_positive';
    if (avgScore > 0.2) return 'positive';
    if (avgScore < -0.6) return 'very_negative';
    if (avgScore < -0.2) return 'negative';
    return 'neutral';
  }

  /**
   * Convierte sentimiento detallado a puntuaci√≥n num√©rica
   */
  private detailedSentimentToScore(sentiment: DetailedSentiment): number {
    switch (sentiment) {
      case 'very_positive': return 1;
      case 'positive': return 0.5;
      case 'neutral': return 0;
      case 'negative': return -0.5;
      case 'very_negative': return -1;
      default: return 0;
    }
  }

  /**
   * Convierte sentimiento b√°sico a puntuaci√≥n num√©rica
   */
  private sentimentToScore(sentiment: SentimentType): number {
    switch (sentiment) {
      case 'positive': return 0.5;
      case 'negative': return -0.5;
      case 'neutral': return 0;
      default: return 0;
    }
  }

  /**
   * Genera insights contextuales basados en m√∫ltiples modelos
   */
  private generateContextualInsights(multiModelResults: MultiModelAnalysis[]): string {
    const modelCount = multiModelResults.length;
    const sentiments = multiModelResults.map(r => r.overallSentiment);
    const avgConfidence = multiModelResults.reduce((sum, r) => sum + r.confidenceScore, 0) / modelCount;

    return `An√°lisis basado en ${modelCount} modelos de IA diferentes. Sentimientos detectados: ${sentiments.join(', ')}. Confianza promedio: ${(avgConfidence * 100).toFixed(1)}%.`;
  }

  /**
   * Limpia respuesta JSON de caracteres problem√°ticos
   */
  private cleanJSONResponse(response: string): string {
    let cleanedResponse = response.trim();
    
    // Buscar el JSON entre ```json y ``` si existe
    const jsonCodeBlockMatch = cleanedResponse.match(/```json\s*([\s\S]*?)\s*```/);
    if (jsonCodeBlockMatch) {
      cleanedResponse = jsonCodeBlockMatch[1].trim();
    }
    
    // Buscar el JSON principal
    const jsonMatch = cleanedResponse.match(/\{[\s\S]*\}/);
    if (jsonMatch) {
      cleanedResponse = jsonMatch[0];
    }
    
    return cleanedResponse
      .replace(/[\u0000-\u001F\u007F-\u009F]/g, '')
      .replace(/,\s*}/g, '}')
      .replace(/,\s*]/g, ']')
      .replace(/\n/g, ' ')
      .replace(/\r/g, '')
      .replace(/\t/g, ' ')
      .replace(/\s+/g, ' ')
      .trim();
  }
}

export default OpenAIService;